# Intel Open_Vino å®éªŒæ–‡æ¡£

**author: @ä¸‰æ°´å¯¿ ğŸ˜¬**

## ä¸€.å®éªŒç¯å¢ƒæ¡ä»¶

1)ç¡¬ä»¶è¦æ±‚ï¼š

Intelç³»åˆ—CPU/GPU ä»¥ä¸‹å®éªŒä¸ºCPU I7-1165G7

2)è½¯ä»¶è¦æ±‚ï¼š

Window Liunx çš†å¯

![Untitled](Intel%20Open_Vino%20%E5%AE%9E%E9%AA%8C%E6%96%87%E6%A1%A3%2002179fc92eaa4c348a1860867da4f8be/Untitled.png)

![Untitled](Intel%20Open_Vino%20%E5%AE%9E%E9%AA%8C%E6%96%87%E6%A1%A3%2002179fc92eaa4c348a1860867da4f8be/Untitled%201.png)

Python 3.7ä»¥ä¸Š

3)Open_Vino Pythonç¯å¢ƒå®‰è£…æµç¨‹

Window & Liunx ç›¸åŒ

- python -m pip install --upgrade pip
- pip install openvino-dev==2023.0.1
- pip install ultralytics==8.0.43
- pip install nncf==2.5.0
- pip install torch==1.13.0+cpu torchvision==0.14.0+cpu torchaudio==0.13.0 --extra-index-url https://download.pytorch.org/whl/cpu

ç­‰å¾…pipå®‰è£…å®Œæ¯•å³å¯

PSï¼šå®‰è£…å®˜ç½‘ç½‘ç«™ [https://www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/download.html?ENVIRONMENT=DEV_TOOLS&OP_SYSTEM=LINUX&VERSION=v_2023_0_1&DISTRIBUTION=PIP](https://www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/download.html?ENVIRONMENT=DEV_TOOLS&OP_SYSTEM=LINUX&VERSION=v_2023_0_1&DISTRIBUTION=PIP)

## äºŒ.æ¨¡å‹è½¬æ¢åŠNncfé‡åŒ–

PSï¼šä»¥ä¸‹æ“ä½œå‡åŸºäºPytorchæ¡†æ¶ä½œä¸ºå®ä¾‹ä¸”ä»¥Yolov8ä½œä¸ºå®ä¾‹å±•ç¤ºã€‚

1)æ¨¡å‹è½¬æ¢åŠæ³•

- Pytorchæ¨¡å‹è½¬æ¢ä¸ºOnnxæ¨¡å‹
    
    ```python
    from ultralytics import YOLO
    #éœ€è¦æ³¨æ„çš„æ˜¯ultralyticsçš„ç‰ˆæœ¬é—®é¢˜8.0.43çš„YOLOç±»ä¸é€‚ç”¨ä¸nè§„æ ¼çš„
    #æ¨¡å‹ï¼Œè€Œä¸”8.0.43ä»¥ä¸Šçš„ç‰ˆæœ¬ä¸æ”¯æŒä¸‹é¢æåˆ°çš„ValåŸºå‡†è¯„ä¼°ã€‚
    model = YOLO('yolov8s.pt') 
    result = model.export(format='onnx') #yolov8åŸç”Ÿè½¬æ¢
    ```
    
- onnxæ¨¡å‹è½¬vinoæ¨¡å‹ï¼ˆxmlï¼‰
    
    ```python
    from openvino.tools import mo
    from openvino.runtime import serialize
    
    #model_pathä¸ºonnxæ¨¡å‹è·¯å¾„
    model = mo.convert_model(model_path)
    #fp32_parhä¸ºvinoæ¨¡å‹ä¿å­˜å‡ºæ¥çš„è·¯å¾„
    serialize(model,fp32_path) #onnx2vino
    ```
    

2)Nncfæ¨¡å‹é‡åŒ–

å‰æå‡†å¤‡ï¼šCoco128æ•°æ®é›†ï¼›     ä¸‹æ–¹ä¸ºä¸‹è½½åœ°å€ï¼š

[https://ultralytics.com/assets/coco128.zip](https://ultralytics.com/assets/coco128.zip)

```python
#åˆ›é€ æ•°æ®coco128
data_source = create_data_source()
pot_data_loader = YOLOv5POTDataLoader(data_source)
#nncfé‡åŒ–æ•°æ®
nncf_calibration_dataset = nncf.Dataset(data_source, transform_fn)
#åˆ›é€ é‡åŒ–ç®—å­
core = Core()
#fp32_parhä¸ºvinoæ¨¡å‹ä¿å­˜å‡ºæ¥çš„è·¯å¾„
ov_model = core.read_model(fp32_path)
q_model = nncf.quantize(
    ov_model,nncf_calibration_dataset,preset=preset,subset_size=subset_size
)#å¼€å§‹nncfé‡åŒ–æ¨¡å‹
nncf_int8_path = f'{model_name}_nncf_int8.xml'
serialize(q_model,nncf_int8_path) #ä¿å­˜å‡ºé‡åŒ–åçš„xmlæ¨¡å‹
```

3)Valæ¨¡å‹åŸºå‡†è¯„ä¼°

- ValåŠæ³•
    
    PS : api.pyå‡æ¥è‡ªIntel Open_Vino notebookå†… æœ¬æºç å†…å¸¦æœ‰
    
    ```python
    from PIL import Image
    from api import *
    from ultralytics import YOLO
    from ultralytics.yolo.utils import DEFAULT_CFG
    from ultralytics.yolo.cfg import get_cfg
    from ultralytics.yolo.data.utils import check_det_dataset
    from openvino.runtime import Core
    
    args = get_cfg(cfg=DEFAULT_CFG)
    args.data = str('coco128.yaml')#yolov8å†…è‡ªå¸¦çš„yamlæ–‡ä»¶
    det_model = YOLO('æ­¤å¤„ä¸ºæ¨¡å‹åœ°å€')
    label_map = det_model.model.names
    
    #è¯„ä¼°å‡½æ•°åŠ è½½
    det_validator = det_model.ValidatorClass(args=args)
    det_validator.data = check_det_dataset(args.data)
    det_data_loader = det_validator.get_dataloader('æ­¤å¤„ä¸ºå›¾ç‰‡å­˜æ”¾çš„åœ°å€å¦‚ï¼šcoco128/images/train2017/', 1)
    det_validator.is_coco = True  #æ•°æ®æ˜¯å¦æ˜¯coco
    det_validator.class_map = ops.coco80_to_coco91_class() #cocoæ ‡æ³¨æœ‰80ç§ï¼Œä½†æ ‡æ³¨åºå·ä¼šæœ‰ç¼ºå¤±æˆ–å¤§äº80ï¼Œç”¨äºå°†æ ‡æ³¨å·å½’åˆ°80å†…
    det_validator.names = det_model.model.names
    det_validator.metrics.names = det_validator.names
    det_validator.nc = det_model.model.model[-1].nc
    
    #å‡†ç¡®åº¦è¯„ä¼°
    #NUM_TEST_SAMPLESä¸ºåŠ è½½å¤šå°‘å›¾ç‰‡è¿›è¡Œè¯„ä¼°
    fp_det_stats = test(det_ov_model, core, det_data_loader, det_validator, num_samples=NUM_TEST_SAMPLES)
    print_stats(fp_det_stats, det_validator.seen, det_validator.nt_per_class.sum())
    ```
    
- Benchmarkè¯„ä¼°
    
    ```powershell
    !benchmark_app -m ä½ çš„æ¨¡å‹çš„è·¯å¾„ -d ä½ çš„ç¡¬ä»¶(CPU/GPU) -api async -shape "[1,3,640,640]â€
    ```
    
- Yolov8s.ptåŸºå‡†è¡¨
    
    Latency :æ£€æµ‹å•ä¸ªç‰©ä½“æ—¶çš„æœ€å°åŠæœ€å¤§å»¶è¿Ÿ ï¼ˆå•ä½ï¼šmsï¼‰ã€‚
    
    mFPS:å¹³è¡¡å¸§ç‡ from benchmarkã€‚
    
    mAP@:50 ï¼šå¯ä»¥ç†è§£ä¸ºåœ¨ioué˜ˆå€¼ä¸º50æ—¶çš„å¹³å‡å‡†åº¦ã€‚
    
    | Type | Latency(ms) | mFPS | mAP@:50 |
    | --- | --- | --- | --- |
    | FP32 | 188.84~403.97 | 13.18 | 0.772 |
    | FP16 | 193.24~403.89 | 13.4 | 0.772 |
    | Int8 | 58.28~116.94 | 43.87 | 0.744 |

4)é‡åŒ–åæ¨¡å‹æ¨ç†åŠæ³•

```python
from api import *
from openvino.runtime import Core
import cv2
import time

def predict(model,cls_maps:dict,obj_path:str,cap:bool=False):
    """
    ä½¿ç”¨Open_Vinoé‡åŒ–åé¢„æµ‹(ç›®æ ‡æ£€æµ‹ï¼‰
    :param model: xmlæ¨¡å‹ï¼ˆé‡åŒ–åçš„æ¨¡å‹ï¼‰
    :param cls_maps: è¾“å…¥dictç±»å‹ï¼Œ{ç¼–å·:å¯¹åº”æ ‡ç­¾}
    :param obj_path: å›¾ç‰‡æˆ–è§†é¢‘è·¯å¾„ï¼Œè®¾ç½®ä¸º'0'ä¸”capä¸ºTrueçš„æ—¶å€™ä½¿ç”¨æ‘„åƒå¤´
    :param cap: æ˜¯å¦ä½¿ç”¨æ‘„åƒå¤´,boolç±»å‹
    :return: å›¾ç‰‡æ¨¡å¼è¿”å›é¢„æµ‹åçš„å›¾ç‰‡ï¼Œè§†é¢‘æ¨¡å¼è¿”å›é¢„æµ‹åçš„è§†é¢‘ï¼Œæ‘„åƒå¤´æ¨¡å¼è¿”å›æ‘„åƒå¤´å½•åˆ¶çš„è§†é¢‘
    """
    label_map = cls_maps
    #ä½¿ç”¨xmlè¿›è¡Œé¢„æµ‹
    core = Core()
    det_ov_model = core.read_model(model)
    device = 'CPU'
    det_compiled_model = core.compile_model(det_ov_model, device)

    if obj_path.split('.')[-1] == '.mp4':
        print('è§†é¢‘æ¨¡å¼')
        cm = cv2.VideoCapture(obj_path)
        while True:
            a,frame = cm.read()
            if a:
                detections = detect(frame, det_compiled_model)[0]
                image_with_boxes = draw_results(detections, frame, label_map)
                cv2.imshow('vid',image_with_boxes)
                if 0xff==ord('q')&cv2.waitKey(1):
                    break
                else:
                    continue
            else:
                print('mp4æœªæ‰“å¼€æˆåŠŸï¼')
                break
    elif obj_path == '0' and cap:
        print('æ‘„åƒå¤´æ¨¡å¼')
        cm = cv2.VideoCapture(4)
        while True:
            a,frame = cm.read()
            if a:
                t1 = time.time()
                detections = detect(frame, det_compiled_model)[0]
                image_with_boxes = draw_results(detections, frame, label_map)
                t2 = time.time()
                ms = int((t2-t1)*1000)
                cv2.putText(image_with_boxes,f'FPS:{1000/ms}',(20,20),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,255,0),2)
                cv2.imshow('cm',image_with_boxes)
                if cv2.waitKey(1)&0xff==ord('q'):
                    break
                else:
                    continue
            else:
                print('æ‘„åƒå¤´æœªæ‰“å¼€æˆåŠŸï¼')
                break
    else:
        print('å›¾ç‰‡æ¨¡å¼æˆ–å…¶ä»–')
        frame = cv2.imread(obj_path)
        detections = detect(frame, det_compiled_model)[0]
        image_with_boxes = draw_results(detections, frame, label_map)
        cv2.imshow('images', image_with_boxes)
        cv2.waitKey(0)
        # cv2.imwrite('result/001.jpg',image_with_boxes)

if __name__ == '__main__':
    predict('yolov8s_nncf_int8.xml',{0:'person'},'0',cap=True)
```